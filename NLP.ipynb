{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f80c20a-5f74-44f0-ac7e-865e68958391",
   "metadata": {},
   "source": [
    "## Import list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61bfcf64-574f-4a3f-a48b-7213b73767cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\samev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\samev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\samev\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords ##Parsing\n",
    "nltk.download('wordnet') ##Lem\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf17e225-6df1-48ab-a379-efe6072a69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text that will be processed\n",
    "sample_text = \"Sam ate sausages. Goodmorning Sam.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a249c-94d4-4120-ba56-846d5e1f0e09",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f527f2f3-8bcb-4842-9821-6a2c1d51aefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All vertexes are marked as unvisited.', 'Add it to the queue.', 'Then explore node and if neighbours are unvisited, add the neighbours to the queue and pop the next node to be visited off of the queue']\n",
      "['All', 'vertexes', 'are', 'marked', 'as', 'unvisited', '.', 'Add', 'it', 'to', 'the', 'queue', '.', 'Then', 'explore', 'node', 'and', 'if', 'neighbours', 'are', 'unvisited', ',', 'add', 'the', 'neighbours', 'to', 'the', 'queue', 'and', 'pop', 'the', 'next', 'node', 'to', 'be', 'visited', 'off', 'of', 'the', 'queue']\n"
     ]
    }
   ],
   "source": [
    "##Split text into sentences\n",
    "sentences = sent_tokenize(sample_text)\n",
    "print(sentences)\n",
    "\n",
    "##Split sentences into words\n",
    "words = word_tokenize(sample_text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8882b210-b0df-4549-97ee-67a75eecb8ba",
   "metadata": {},
   "source": [
    "## Removal of stopwords / punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "892e157a-187b-45f9-8172-0bd786c173d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All vertexes are marked as unvisited  Add it to the queue  Then explore node and if neighbours are unvisited  add the neighbours to the queue and pop the next node to be visited off of the queue\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "Parsed_text = re.sub(r\"[^a-zA-Z0-9]\",\" \", sample_text) ## Removes all punctuation\n",
    "print(Parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57424e6d-b999-4003-9278-d0ea9e89e3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'vertexes', 'marked', 'unvisited', 'Add', 'queue', 'Then', 'explore', 'node', 'neighbours', 'unvisited', 'add', 'neighbours', 'queue', 'pop', 'next', 'node', 'visited', 'queue']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\samev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "words = word_tokenize(Parsed_text) ## To split up the depunctuated text\n",
    "words = [w for w in words if w not in stopwords.words(\"english\")] ## Cycles through all elements and compares with stopword list\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ed5faf-ffab-4b72-ad5b-dfead83ff4a9",
   "metadata": {},
   "source": [
    "## Stemming and lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ef33a36-2692-483a-afff-cedc37a965e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'vertex', 'mark', 'unvisit', 'add', 'queue', 'then', 'explor', 'node', 'neighbour', 'unvisit', 'add', 'neighbour', 'queue', 'pop', 'next', 'node', 'visit', 'queue']\n"
     ]
    }
   ],
   "source": [
    "## Stemming\n",
    "from nltk.stem.porter import PorterStemmer as ps\n",
    "stemmed = [ps().stem(w) for w in words]\n",
    "print (stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f48b5c2f-2cbb-4fd5-b90d-bcd98935e7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'vertex', 'marked', 'unvisited', 'Add', 'queue', 'Then', 'explore', 'node', 'neighbour', 'unvisited', 'add', 'neighbour', 'queue', 'pop', 'next', 'node', 'visited', 'queue']\n"
     ]
    }
   ],
   "source": [
    "##Lemmatising\n",
    "from nltk.stem.wordnet import WordNetLemmatizer as WNL\n",
    "lemmatised = [WNL().lemmatize(w) for w in words]\n",
    "print(lemmatised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97378364-e77a-4d6d-b7bd-a0121b279e6e",
   "metadata": {},
   "source": [
    "## Speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "14f47d8e-c41a-4593-8535-f02c6e8190e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\samev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('All', 'DT'),\n",
       " ('vertexes', 'NNS'),\n",
       " ('marked', 'VBD'),\n",
       " ('unvisited', 'JJ'),\n",
       " ('Add', 'NNP'),\n",
       " ('queue', 'NN'),\n",
       " ('Then', 'RB'),\n",
       " ('explore', 'RB'),\n",
       " ('node', 'JJ'),\n",
       " ('neighbours', 'NNS'),\n",
       " ('unvisited', 'JJ'),\n",
       " ('add', 'VBP'),\n",
       " ('neighbours', 'NNS'),\n",
       " ('queue', 'JJ'),\n",
       " ('pop', 'VBP'),\n",
       " ('next', 'JJ'),\n",
       " ('node', 'NN'),\n",
       " ('visited', 'VBD'),\n",
       " ('queue', 'NN')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "from nltk import pos_tag \n",
    "pos_tag(words) ## Assigns a type to each word eg. verb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1260c4e2-2e3e-4405-ae35-60fae6df0916",
   "metadata": {},
   "source": [
    "## Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02b2ee52-d617-4dee-80bb-7731de2db257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\samev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\samev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  All/DT\n",
      "  vertexes/NNS\n",
      "  marked/VBD\n",
      "  unvisited/JJ\n",
      "  Add/NNP\n",
      "  queue/NN\n",
      "  Then/RB\n",
      "  explore/RB\n",
      "  node/JJ\n",
      "  neighbours/NNS\n",
      "  unvisited/JJ\n",
      "  add/VBP\n",
      "  neighbours/NNS\n",
      "  queue/JJ\n",
      "  pop/VBP\n",
      "  next/JJ\n",
      "  node/NN\n",
      "  visited/VBD\n",
      "  queue/NN)\n"
     ]
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n",
    "from nltk import ne_chunk\n",
    "ner_tree = ne_chunk(pos_tag(words))\n",
    "print(ner_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae35f6-7d40-4e66-93d6-c3aa00c631ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
