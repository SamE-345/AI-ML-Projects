{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6adcdf1-8b06-4372-8cdf-f25a5c8e975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip install torch\n",
    "import torch\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "##!pip install torchvision\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd277175-f925-413d-81fe-1fac47ea4599",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
    "])\n",
    "\n",
    "Train_Set = torchvision.datasets.MNIST(r'C:\\Users\\samev\\OneDrive\\Coding\\Machine Learning\\Handwriting_Recognition', download=True, transform=transform, train=True)\n",
    "Train_data_loader = torch.utils.data.DataLoader(Train_Set,batch_size=64,shuffle=True)\n",
    "\n",
    "Test_Set = torchvision.datasets.MNIST(r'C:\\Users\\samev\\OneDrive\\Coding\\Machine Learning\\Handwriting_Recognition', download=True, transform=transform, train=False)\n",
    "Train_data_loader = torch.utils.data.DataLoader(Train_Set,batch_size=64,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d1b09b-3633-4ab4-83ca-3e005e5bcf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        \n",
    "        # 1. Input Layer Decision:\n",
    "        # Each MNIST image is 28x28 pixels, which we flatten into 784 features.\n",
    "        # We map these 784 features to a hidden layer.\n",
    "        self.fc1 = nn.Linear(784, 128)  # 784 input features to 128 neurons.\n",
    "        # Choosing 128 neurons is a common starting point for balancing model capacity and training speed.\n",
    "        \n",
    "        # 2. Hidden Layer(s):\n",
    "        # We add a second hidden layer to allow the network to learn more complex patterns.\n",
    "        self.fc2 = nn.Linear(128, 64)  # Reducing dimensionality from 128 to 64 neurons.\n",
    "        # This reduction helps the model learn hierarchical representations.\n",
    "        \n",
    "        # 3. Output Layer:\n",
    "        # The task is to classify images into 10 classes (digits 0-9).\n",
    "        # Therefore, the output layer has 10 neurons.\n",
    "        self.fc3 = nn.Linear(64, 10)  # Mapping 64 features to 10 output classes.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 4. Flattening:\n",
    "        # The input x comes in shape [batch_size, 1, 28, 28]. We flatten it to [batch_size, 784].\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # 5. First Hidden Layer + Activation:\n",
    "        # Applying a linear transformation followed by ReLU activation introduces non-linearity.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # 6. Second Hidden Layer + Activation:\n",
    "        # Again, we transform the data and apply ReLU.\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # 7. Output Layer:\n",
    "        # The final linear layer outputs raw scores (logits) for each of the 10 classes.\n",
    "        # We typically apply softmax later (or incorporate it in the loss function, like with CrossEntropyLoss).\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "624a4c81-4d97-4c7a-a289-677a5fde16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN()\n",
    "\n",
    "# Define the loss function. CrossEntropyLoss is appropriate for multi-class classification.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Choose an optimizer (Adam in this case) to update model weights.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------\n",
    "# Step 3: Train the Model\n",
    "# ------------------------------\n",
    "\n",
    "num_epochs = 5  # You can adjust this based on your needs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over the training DataLoader\n",
    "    for images, labels in Train_data_loader:\n",
    "        # Zero the parameter gradients to avoid accumulating them\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model.\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute the loss between predicted outputs and actual labels.\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters.\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters using the gradients.\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f44be15-d431-4caa-a64e-5bd8dc7f3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    index = r.randint(0, len(Test_Set)-1)\n",
    "    sample_img, sample_label = Test_Set[index]\n",
    "    image_np = sample_img.numpy().squeeze()\n",
    "    plt.imshow(image_np, cmap=\"gray\")  # Use 'gray' colormap for grayscale images\n",
    "    \n",
    "    plt.axis(\"off\")  # Hide axis for better visualization\n",
    "    \n",
    "    \n",
    "    \n",
    "    # The model expects a batch dimension, so we add one using unsqueeze.\n",
    "    sample_img = sample_img.unsqueeze(0)  # Shape: [1, 1, 28, 28]\n",
    "    \n",
    "    # Make a prediction\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        output = model(sample_img)\n",
    "        # Get the predicted class (digit) by finding the index with the highest output score.\n",
    "        _, predicted_label = torch.max(output, 1)\n",
    "    \n",
    "    print(f\"Predicted: {predicted_label.item()}, Actual: {sample_label}\")\n",
    "    plt.title(f\"Actual: {sample_label}, Predicted: {predicted_label.item()}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36a343ee-7872-4858-b8c7-780ea9e96904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0, Actual: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e08b984-1aa1-42f6-84ac-78fcf8f792ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
